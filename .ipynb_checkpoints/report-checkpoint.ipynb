{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <center> <font color=Blue> Computer Vision </font> </center>\n",
    "## <center> Scene Recognition Using Neural Networks </center>\n",
    "\n",
    "***\n",
    "\n",
    "## S.Alireza Mousavizade\n",
    "\n",
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "     در تمرین سری ۳ قسمت ۴ مساله\n",
    "    <span style=\"direction: rtl\">Scene Recognition</span>\n",
    "    را به کمک\n",
    "    <span style=\"direction: rtl\">SVM</span>\n",
    "    حل کردیم. در این تمرین همان مساله با همان داده های ورودی را این بار به کمک\n",
    "    <span style=\"direction: rtl\">Neural Network</span>\n",
    "    حل میکنیم.\n",
    "</p>\n",
    "\n",
    "<hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    در این تمرین از کتابخانه\n",
    "    <span style=\"direction: rtl\">Pytorch</span>\n",
    "    برای یادگیری مدل شبکه عصبی استفاده شده است. همچنین برای بررسی کارکرد مدل شبکه عصبی از\n",
    "    <span style=\"direction: rtl\">TensorBoard</span>\n",
    "    استفاده شده است. دستورات زیر کتابخانه های مورد نیاز مذکور را به کمک\n",
    "    <span style=\"direction: rtl\">Anaconda</span>\n",
    "    نصب میکند.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install pytorch torchvision torchaudio cudatoolkit -c pytorch\n",
    "\n",
    "pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    همچنین پکیح های زیر در فرآیند اجرای برنامه مورد نیاز است.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"float: right; block; font-family: 'Vazir'; direction: rtl; color: red\"> نکات مهم در پیاده سازی</span>\n",
    "\n",
    "<ol style=\"direction:rtl;text-align:right;\">\n",
    "    <li style=\"font-family: 'Vazir Thin';\">\n",
    "        با توجه به\n",
    "        <a href=\"https://towardsdatascience.com/7-tips-for-squeezing-maximum-performance-from-pytorch-ca4a40951259\">این</a>\n",
    "        مقاله نکات زیر در پیاده سازی انجام شده است:\n",
    "        برای افزایش سرعت پردازش مدل در\n",
    "       <span style=\"direction: rtl\">GPU</span>\n",
    "    ها، آرگومان های\n",
    "        <code style=\"\">&#x200E;num_worker=4&#x200E;</code>\n",
    "    و\n",
    "        <code style=\"\">&#x200E;pin_memory=True&#x200E;</code>\n",
    "        در سازنده کلاس\n",
    "       <span style=\"direction: rtl\">Dataloader</span>\n",
    "        ست شده است.\n",
    "    </li>\n",
    "    <li style=\"font-family: 'Vazir Thin';\">\n",
    "        متد\n",
    "       <span style=\"direction: rtl\">.item</span>\n",
    "        از کلاس\n",
    "       <span style=\"direction: rtl\">Tensor</span>\n",
    "        ، در واقع عدد درون یک تنسور با یک درایه را خروجی می دهد که قابلیت نگه داشته شدن در\n",
    "       <span style=\"direction: rtl\">GPU</span>\n",
    "        را ندارد. بنابراین با هربار فراخوانی تابع مذکور یک انتقال از\n",
    "               <span style=\"direction: rtl\">GPU</span>\n",
    "        به\n",
    "               <span style=\"direction: rtl\">CPU</span>\n",
    "        داریم که هزینه پردازشی بسیاری دارد.\n",
    "        به این ترتیب باید از فراخوانی این تابع در کد حتی الامکان خودداری شود. (\n",
    "        به صورت مشابه برای\n",
    "        متد های\n",
    "               <code style=\"\">&#x200E;.cpu()&#x200E;</code>\n",
    "               و\n",
    "               <code style=\"\">&#x200E;.numpy()&#x200E;</code>\n",
    "          نیز این موضوع برقرار است.\n",
    "        )\n",
    "    </li>\n",
    "    <li style=\"font-family: 'Vazir Thin';\">\n",
    "        برای تعریف تنسور لازم است مستقیما تنسور را در\n",
    "               <span style=\"direction: rtl\">GPU</span>\n",
    "        تعریف کنیم.\n",
    "        تکه کد زیر تنسور را ابتدا در\n",
    "               <span style=\"direction: rtl\">CPU</span>\n",
    "        تعریف میکند و سپس آن را به\n",
    "                       <span style=\"direction: rtl\">GPU</span>\n",
    "            منتقل میکند:\n",
    "        <br>\n",
    "        <center> <code style=\"\">t = torch.rand(2, 2).cuda()&#x200E;</code> </center>\n",
    "        <br>\n",
    "        که به جای آن باید از تکه کد زیر استفاده کرد که تنسور را مستقیما در\n",
    "                       <span style=\"direction: rtl\">GPU</span>\n",
    "        تعریف میکند:\n",
    "        <br>\n",
    "        <center> <code style=\"\">t = torch.rand(2, 2, device=running_device)&#x200E;</code> </center>\n",
    "        <br>\n",
    "    </li>\n",
    "    <li style=\"font-family: 'Vazir Thin';\">\n",
    "        پیاده سازی\n",
    "           <span style=\"direction: rtl\">Pytorch</span>\n",
    "با معماری پیپر اصلی\n",
    "           <span style=\"direction: rtl\">AlexNet</span>\n",
    "       تفاوت هایی در لایه اول و دوم\n",
    "          <span style=\"direction: rtl\">Convolutional</span>\n",
    "دارد. این موضوع در قسمت های ۱و۲و۳ در نظر گرفته شده است.\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Dataset\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    داده های\n",
    "        <span style=\"direction: rtl\">Train</span>\n",
    "    و\n",
    "        <span style=\"direction: rtl\">Validation</span>\n",
    "    برای آموزش مدل شبکه عصبی همان داده های تمرین ۳ قسمت ۴ هستند که در فولدر\n",
    "    <span style=\"direction: rtl\">Data</span>\n",
    "    آمده اند که شامل ۱۵ کلاس مختلف از صحنه های متفاوت هستند که هر عکس تقریبا\n",
    "        <span style=\"direction: rtl\">\n",
    "        256 &#x2715; 256\n",
    "         </span>\n",
    "    است.\n",
    "    همچنین باید به این نکته توجه داشت که تصاویر ورودی شبکه عصبی\n",
    "        <span style=\"direction: rtl\">AlexNet</span>\n",
    "    تصاویر رنگی با چنل های قرمز، سبز و آبی هستند. به این ترتیب\n",
    "    یک راه حل ممکن برای حل این موضوع این است که هر تصویر\n",
    "            <span style=\"direction: rtl\">Gray Scale</span>\n",
    "    دیتاست مذکور را ۳ بار تکرار کنیم تا تصویر به یک تصویر با ۳ چنل قرمز، سبر تبدیل شود.\n",
    "</p>\n",
    "\n",
    "***\n",
    "\n",
    "## Load Data\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "     داده های\n",
    "        <span style=\"direction: rtl\">Train</span>\n",
    "    و\n",
    "        <span style=\"direction: rtl\">Validation</span>\n",
    "     به کمک کلاس\n",
    "        <code style=\"\">&#x200E;torchvision.datasets.ImageFolder&#x200E;</code>\n",
    "       هر یک در قالب یک دیتاست لود میشود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a55583273dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_preprocess_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_preprocess_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_directory' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(train_directory, transform=train_preprocess_transforms)\n",
    "validation_dataset = torchvision.datasets.ImageFolder(validation_directory, transform=validation_preprocess_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    همچنین کلاس\n",
    "        <code style=\"\">&#x200E;data.DataLoader&#x200E;</code>\n",
    "    دیتاست های داده های آموزش و اعتبارسنجی را به\n",
    "        <span style=\"direction: rtl\">Mini Batch</span>\n",
    "        هایی با اندازه داده شده افراز می کند.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "                                   drop_last=drop_last, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "validation_dataloader = data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "                                        drop_last=drop_last, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به این ترتیب در فرآیند یادگیری، در هر\n",
    "        <span style=\"direction: rtl\">Epoch</span>\n",
    "    به صورت زیر در هر مرحله یک\n",
    "        <span style=\"direction: rtl\">Batch</span>\n",
    "    از داده ها به مدل داده میشود. (که البته در فاز اعتبارسنجی لزوما لازم نیست داده ها به صورت\n",
    "        <span style=\"direction: rtl\">Batch</span>\n",
    "        به مدل داده شوند.)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train Phase\n",
    "for i, batch in enumerate(data_loaders[TRAIN_STR]):\n",
    "    ...\n",
    "\n",
    "# Validation Phase\n",
    "for i, batch in enumerate(data_loaders[VALIDATION_STR]):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Hyper Parameter Tuning\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    برای تنظیم کردن مقادیر ها هایپرپارامترها می توان از روش\n",
    "        <span style=\"direction: rtl\">Grid Search</span>\n",
    "    روی مقادیر هایپرپارامترها استفاده کرد. (یک راه دیگر این است که مقادیر هایپرپارامترها به صورت تصادفی به تعداد دفعات مشخص مقدار دهی شوند تا تقریب مناسبی از مقادیر هایپرپارامترها بدست آید.)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyper_parameters_space_dict = {\n",
    "    SIZE_STR: [256, 224, 128],\n",
    "    BATCH_SIZE_STR: [6, 12, 24, 48, 96],\n",
    "    LEARNING_RATE_STR: [1e-3, 1e-4, 1e-5],\n",
    "    EPOCH_NUMBER_STR: [120],\n",
    "    WEIGHT_DECAY_STR: [1e-3, 1e-4, 1e-5]\n",
    "}\n",
    "\n",
    "model, configs, accuracy = NeuralNetworkTrainer(data_directory).\n",
    "hyper_parameter_tune(hyper_parameters_space_dict).\n",
    "get_best_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Parts Implementations:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    در هر قسمت موارد زیر توضیح داده میشود:\n",
    "</p>\n",
    "\n",
    "- Data (Data Augmentation: Transforms)\n",
    "- Neural Network Model\n",
    "- Weight Initialization\n",
    "- Loss Function\n",
    "- Optimizer\n",
    "- Learning Rate Scheduler\n",
    "\n",
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "## Part 1\n",
    "\n",
    "***\n",
    "\n",
    "### Data:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    در ابندا طول و عرض داده های آموزش و اعتبارسنجی با توجه به تاپل\n",
    "    <span style=\"direction: rtl\">size</span>\n",
    "    تغییر میکند.\n",
    "    <br>\n",
    "    به علت تعداد بسیار محدود مجموعه آموزش، از تکنیک\n",
    "    <span style=\"direction: rtl\">Data Augmentation</span>\n",
    "    استفاده میکنیم تا عملا اندازه مجموعه آموزش را افزایش و به داده های آموزش تنوع دهیم. همچنین داده های ورودی به کمک میانگین و انحراف معیاری که به صورت\n",
    "    تجربی از داده های دیتاست\n",
    "        <span style=\"direction: rtl\">ImageNet</span>\n",
    "    بدست آمده نرمال میشوند. این تبدیل روی داده های\n",
    "        <span style=\"direction: rtl\">Validation</span>\n",
    "    نیز اعمال میشود.\n",
    "    رشته کد زیر این قسمت را انجام میدهد:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "probability = .5\n",
    "# ImageNet mean and std\n",
    "mean, standard_deviation = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "train_preprocess_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=size, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.RandomHorizontalFlip(p=probability),\n",
    "    transforms.RandomPerspective(p=probability, distortion_scale=.5, ),\n",
    "    transforms.RandomRotation(degrees=(-4, +4)),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, standard_deviation)\n",
    "])\n",
    "\n",
    "validation_preprocess_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=size, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, standard_deviation)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Neural Network Model:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    معماری مدل شبکه عصبی با توجه به توضیحات این قسمت از داک تمرین به صورت زیر پیاده سازی میشود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Part1NN(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Part1NN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=4),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(96 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به صورت زیر از مدل تعریف شده استفاده میشود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "part1_nn = Part1NN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Weight Initialization:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    مقادیر اولیه وزن های مدل طبق روش\n",
    "        <span style=\"direction: rtl\">He Initialization</span>\n",
    "    مقدار دهی میشوند. این روش در مقاله\n",
    "</pr>\n",
    "\n",
    "#### <center> Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification - He, K. et al. (2015) </center>\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "     ارایه شده است.\n",
    "    به این ترتیب که برای تابع فعال سازی\n",
    "        <span style=\"direction: rtl\">Relu , Leaky Relu</span>\n",
    "    بهتر است از این مقداردهی اولیه استفاده شود.\n",
    "    پیاده سازی این قسمت به صورت زیر است. (خود کتابخانه از این متد استفاده میکند.)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fully connected layer\n",
    "init.kaiming_uniform_(layer.weight, a=math.sqrt(3))\n",
    "if layer.bias is not None:\n",
    "    fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
    "    bound = 1 / math.sqrt(fan_in)\n",
    "    init.uniform_(layer.bias, -bound, bound)\n",
    "\n",
    "# Convolutional layer\n",
    "init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
    "if layer.bias is not None:\n",
    "    fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
    "    bound = 1 / math.sqrt(fan_in)\n",
    "    init.uniform_(layer.bias, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Loss Function:\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    برای این قسمت از\n",
    "            <span style=\"direction: rtl\">Cross Entropy Loss</span>\n",
    "    استفاده شده است.\n",
    "    که به نوعی دو روش\n",
    "            <span style=\"direction: rtl\">LogSoftmax</span>\n",
    "    و\n",
    "            <span style=\"direction: rtl\">NLLLoss</span>\n",
    "    را ترکیب میکند. توضیحات نحوه بدست آوردن این تابع در\n",
    "    <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\">اینحا</a>\n",
    "    آمده است.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Optimizer:\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    برای این قسمت از\n",
    "            <span style=\"direction: rtl\">Adam</span>\n",
    "    استفاده شده است.\n",
    "    (در مقاله برای آموزش مدل\n",
    "        <span style=\"direction: rtl\">AlexNet</span>\n",
    "    از\n",
    "        <span style=\"direction: rtl\">SGD</span>\n",
    "    استفاده شده است.)\n",
    "    <br>\n",
    "    ضریب\n",
    "        <span style=\"direction: rtl\">weight_decay_</span>\n",
    "در واقع نقشی مشابه نقش ضریب \t&lambda; در ترم\n",
    "        <span style=\"direction: rtl\">L2 Regularization</span>\n",
    "    که به صورت:\n",
    "</p>\n",
    "\n",
    "___\n",
    "\n",
    "<center>     $\\mathbf{ \\tilde{E}(w)=E(w) + \\frac{\\lambda}{2}w^2 }$   </center>\n",
    "\n",
    "___\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    است، دارد. به این ترتیب که در هر مرحله وزن های شبکه به صورت زیر بروزرسانی می شود:\n",
    "</p>\n",
    "\n",
    "___\n",
    "\n",
    "<center> $\\mathbf{w_i \\leftarrow (1 - \\eta \\lambda)w_i - \\eta \\frac{\\partial E}{\\partial w_i}}$ </center>\n",
    "\n",
    "___\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به این ترتیب این ضریب مانع از بیش از حد بزرگ شدن ضرایب و پیچیدگی بیش از حد مدل می شود، بنابراین از\n",
    "        <span style=\"direction: rtl\">Overfit</span>\n",
    "    شدن مدل جلوگیری می شود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weight_decay_ = 1e-3\n",
    "optimizer = optim.Adam(params=part1_nn.parameters(),\n",
    "                       lr=lr,\n",
    "                       weight_decay=weight_decay_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "\n",
    "### Learning Rate Scheduler:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    برای این قسمت از\n",
    "            <span style=\"direction: rtl\">optim.lr_scheduler.ExponentialLR</span>\n",
    "    استفاده شده است. که در هر مرحله\n",
    "            <span style=\"direction: rtl\">Learning Rate</span>\n",
    "    را در عدد کوچکتر از ۱ گاما ضرب می کند.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gamma = .99\n",
    "lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "## Part 2\n",
    "\n",
    "\n",
    "### Data:\n",
    "### Weight Initialization:\n",
    "### Loss Function:\n",
    "### Optimizer:\n",
    "### Learning Rate Scheduler:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    این بخش ها مشابه قسمت قبل انجام می شود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Neural Network Model:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    معماری مدل شبکه عصبی با توجه به توضیحات این قسمت از داک تمرین به صورت زیر پیاده سازی میشود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Part2NN(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Part2NN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به صورت زیر از مدل تعریف شده استفاده میشود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "part2_nn = Part2NN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "## Part 3\n",
    "\n",
    "### Data:\n",
    "### Weight Initialization:\n",
    "### Loss Function:\n",
    "### Optimizer:\n",
    "### Learning Rate Scheduler:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    این بخش ها مشابه قسمت قبل انجام می شود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Neural Network Model:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    معماری مدل شبکه عصبی با توجه به توضیحات این قسمت از داک تمرین به صورت زیر پیاده سازی میشود. (بر اساس مستندات کتابخانه\n",
    "        <span style=\"direction: rtl\">Pytorch</span>\n",
    "لایه\n",
    "        <span style=\"direction: rtl\">Average Pooling</span>\n",
    "    بعد از مجموعه لایه\n",
    "            <span style=\"direction: rtl\">features</span>\n",
    "    اضافه شده است.\n",
    "    )\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Part3NN(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Part3NN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به صورت زیر از مدل تعریف شده استفاده میشود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "part3_nn = Part3NN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "## Additional Layers\n",
    "\n",
    "### Batch Normalization Layer:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "       در این سه بخش، میتوان در ابتدای مجموعه\n",
    "                   <span style=\"direction: rtl\">Learning Rate</span>\n",
    "    و قبل از تابع فعال سازی\n",
    "            <span style=\"direction: rtl\">Learning Rate</span>\n",
    "    یک لایه\n",
    "                <span style=\"direction: rtl\">Learning Rate</span>\n",
    "    قرار داد. این لایه اولین بار در مقاله\n",
    "            <span style=\"direction: rtl\">\n",
    "                Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n",
    "            </span>\n",
    "    ارایه شده است. به طوری که تابع زیر روی هر ورودی اعمال میشود. (پارامترهای گاما و بتا به طور پیش فرض به ترتیب برابر ۱ و ۰ مقداردهی می شوند.)\n",
    "</p>\n",
    "\n",
    "***\n",
    "\n",
    "<center> $\\mathbf{y = \\frac{x - \\mathrm{E}[x]}{\\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta}$ </center>\n",
    "\n",
    "***\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    که مقادیر امیدریاضی و واریانس برابر میانگین و واریانس نمونه ای\n",
    "        <span style=\"direction: rtl\">Mini Batch</span>\n",
    "    است.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self.classifier = nn.Sequential(\n",
    "    ...,\n",
    "    nn.BatchNorm1d(4096, ),\n",
    "    ...,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "### Drop Out Layer:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "       در این سه بخش، همچنین میتوان از لایه\n",
    "                   <span style=\"direction: rtl\">DropOut</span>\n",
    "    دز میان لایه های\n",
    "            <span style=\"direction: rtl\">Fully Connected</span>\n",
    "    استفاده کرد.\n",
    "    اضافه کردن این لایه همانطور که در کلاس اشاره شد، باعث افزایش قدرت\n",
    "            <span style=\"direction: rtl\">Generalization</span>\n",
    "    و\n",
    "            <span style=\"direction: rtl\">Overfit</span>\n",
    "    نشدن\n",
    "مدل می شود.\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    که مقادیر امیدریاضی و واریانس برابر میانگین و واریانس نمونه ای\n",
    "        <span style=\"direction: rtl\">Mini Batch</span>\n",
    "    است.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self.classifier = nn.Sequential(\n",
    "    ...,\n",
    "    nn.Dropout(),\n",
    "    ...,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "\n",
    "## Part 4\n",
    "\n",
    "### Data:\n",
    "### Loss Function:\n",
    "### Optimizer:\n",
    "### Learning Rate Scheduler:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    این بخش ها مشابه قسمت قبل انجام می شود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Neural Network Model:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    در این قسمت برخلاف ۳ قسمت قبل از مدل شبکه عصبی از پیش آموزش داده شده استفاده می کنیم که به صورت زیر قابل فراخوانی است:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alex_net: models.AlexNet = models.alexnet(pretrained=True, progress=True)\n",
    "\n",
    "last_classifier_layer_input_features_number = alex_net.classifier[6].in_features\n",
    "fully_connected_layer = nn.Linear(last_classifier_layer_input_features_number, num_classes)\n",
    "alex_net.classifier._modules['6'] = fully_connected_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "به این صورت که تنها لایه آخر آن با توجه به تعداد کلاس های مساله جدید، با یک لایه جدید\n",
    "        <span style=\"direction: rtl\">Fully Connected</span>\n",
    "    جایگزین می شود.\n",
    "</p>\n",
    "\n",
    "***\n",
    "\n",
    "### Weight Initialization:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    بر خلاف قسمت قبل، در این بخش وزن های مدل شبکه عصبی از پیش آموزش دیده شده در ۷ لایه ابتدایی حفظ می شود و برای لایه آخر که با لایه آخر معماری\n",
    "        <span style=\"direction: rtl\">AlexNet</span>\n",
    "    جایگزین شد،\n",
    "    مقادیر اولیه وزن های مدل طبق روش\n",
    "        <span style=\"direction: rtl\">He Initialization</span>\n",
    "    مقدار دهی میشوند.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fully connected layer\n",
    "init.kaiming_uniform_(fully_connected_layer.weight, a=math.sqrt(3))\n",
    "if layer.bias is not None:\n",
    "    fan_in, _ = init._calculate_fan_in_and_fan_out(fully_connected_layer.weight)\n",
    "    bound = 1 / math.sqrt(fan_in)\n",
    "    init.uniform_(fully_connected_layer.bias, -bound, bound)\n",
    "\n",
    "# Convolutional layer\n",
    "init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
    "if layer.bias is not None:\n",
    "    fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
    "    bound = 1 / math.sqrt(fan_in)\n",
    "    init.uniform_(layer.bias, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Freeze Pretrained Layers Weights\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    برای فریز کردن مقادیر وزن های لایه های از پیش آموزش داده شده به صورت زیر عمل می کنیم.\n",
    "</pr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# freeze pretrained layers weights\n",
    "alex_net: models.AlexNet = models.alexnet(pretrained=True, progress=True)\n",
    "for parameter in alex_net.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "fully_connected_layer.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "\n",
    "## Part 5\n",
    "\n",
    "### Data:\n",
    "### Loss Function:\n",
    "### Optimizer:\n",
    "### Learning Rate Scheduler:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    این بخش ها مشابه قسمت قبل انجام می شود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Neural Network Model:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "   در این قسمت برخلاف قسمت ۳ قسمت ابتدایی، از مدل شبکه عصبی از پیش آموزش داده شده استفاده می کنیم که به صورت زیر قابل فراخوانی است.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alex_net: models.AlexNet = models.alexnet(pretrained=True, progress=True)\n",
    "\n",
    "last_classifier_layer_input_features_number = alex_net.classifier[6].in_features\n",
    "fully_connected_layer = nn.Linear(last_classifier_layer_input_features_number, num_classes)\n",
    "alex_net.classifier._modules['6'] = fully_connected_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "به این صورت که تنها لایه آخر آن با توجه به تعداد کلاس های مساله جدید، با یک لایه جدید\n",
    "        <span style=\"direction: rtl\">Fully Connected</span>\n",
    "    جایگزین می شود.\n",
    "</p>\n",
    "\n",
    "***\n",
    "\n",
    "### Weight Initialization:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    بر خلاف ۳ قسمت ابتدایی، در این بخش وزن های مدل شبکه عصبی از پیش آموزش دیده شده در ۷ لایه ابتدایی حفظ می شود\n",
    "    و\n",
    "     بر خلاف قسمت ۴\n",
    "   در این بخش مقادیر وزن های لایه های از پیش آموزش داده شده فریز نمی شوند تا در طی فرآیند آموزش، با توجه به مناسب بودن مقدار دهی ابتدایی وزن ها (وزن ها از مدلی که روی دیتاست\n",
    "        <span style=\"direction: rtl\">ImageNet</span>\n",
    "   آموزش دیده است، مقداردهی اولیه می شوند.\n",
    "    )\n",
    "    تنظیم دقیق\n",
    "    (\n",
    "        <span style=\"direction: rtl\">Fine Tune</span>\n",
    "    )\n",
    "    شوند.\n",
    "     و برای لایه آخر که با لایه آخر معماری\n",
    "        <span style=\"direction: rtl\">AlexNet</span>\n",
    "    جایگزین شد،\n",
    "    مقادیر اولیه وزن های مدل طبق روش\n",
    "        <span style=\"direction: rtl\">He Initialization</span>\n",
    "    مقدار دهی میشوند.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fully connected layer\n",
    "init.kaiming_uniform_(fully_connected_layer.weight, a=math.sqrt(3))\n",
    "if layer.bias is not None:\n",
    "    fan_in, _ = init._calculate_fan_in_and_fan_out(fully_connected_layer.weight)\n",
    "    bound = 1 / math.sqrt(fan_in)\n",
    "    init.uniform_(fully_connected_layer.bias, -bound, bound)\n",
    "\n",
    "# Convolutional layer\n",
    "init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
    "if layer.bias is not None:\n",
    "    fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
    "    bound = 1 / math.sqrt(fan_in)\n",
    "    init.uniform_(layer.bias, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "\n",
    "### Fine Tune Pretrained Layers Weights\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    برای تنظیم دقیق کافی است کردن مقادیر وزن های لایه های از پیش آموزش داده شده و لایه جدید جایگزین شده در هر مرحله بروزرسانی شوند.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "# Parts Results:\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "     مشاهده معماری شبکه عصبی به صورت بصری، یک مجموعه تصادفی کوچک از تصاویر به کار گرفته شده برای فاز آموزش، نمودار دقت و خسارت و ...\n",
    "    با اجرای دستور\n",
    "            <code style=\"\">tensorboard --logdir=runs</code>\n",
    "    و باز کردن لینک گفته شده در مرورگر به کمک ابزار\n",
    "        <span style=\"direction: rtl\">Tensorboard</span>\n",
    "    ممکن است.\n",
    "    نمودارهای خسارت و دقت برای هر قسمت در ادامه آمده است.\n",
    "</p>\n",
    "\n",
    "***\n",
    "\n",
    "## Part 1\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به ازای مقادیر هایپر پارامترهای:\n",
    "</p>\n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| Input Size | 256 |\n",
    "| Batch Size | 12 |\n",
    "| Learning Rate | $10^{-4}$ |\n",
    "| Weight Decay | $10^{-4}$ |\n",
    "| Epochs Number | 60 |\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    نمودارهای خسارت بر حسب شماره\n",
    "        <span style=\"direction: rtl\">Epoch</span>\n",
    "    و دقت بر حسب شماره\n",
    "            <span style=\"direction: rtl\">Epoch</span>\n",
    "    به صورت زیر است.\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part1/accuracy.png' alt='missing' />\n",
    "        <figcaption>Accuracy-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part1/loss.png' alt='missing' />\n",
    "        <figcaption>Loss-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "</center>\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    که در کمترین خسارت، دقتی برابر ۷۲ درصد دارد.\n",
    "</p>\n",
    "\n",
    "## <span style=\"float: right; block; font-family: 'Vazir'; direction: rtl; color: red\">چرا دقت در فاز اعتبارسنجی بیشتر از دفت در فاز آموزش است؟</span>\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    طبق توضیجات\n",
    "    <a href=\"https://www.tensorflow.org/tutorials/images/transfer_learning#learning_curves\">این</a>\n",
    "    مقاله، علت اصلی این نتیجه وجود لایه های\n",
    "        <span style=\"direction: rtl\">Tensorboard</span>\n",
    "    و\n",
    "        <span style=\"direction: rtl\">Tensorboard</span>\n",
    "    می باشد، زیرا این لایه ها در فاز اعتبارسنجی غیرفعال می شوند و تنها در فاز آموزش فعال هستند. همچنین\n",
    "    مجموعه آموزش بنا به تبدیلاتی که به فصد\n",
    "        <span style=\"direction: rtl\">Data Augmentation</span>\n",
    "    روی آن اعمال کرده ایم، مجموعه داده به مراتب عمومی تر و پیچیده تری است که این مورد روی دقت در فاز آموزش و اعتبارسنجی و تفاوت آن ها اثرگذار است.\n",
    "</p>\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## Part 2\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به ازای مقادیر هایپر پارامترهای:\n",
    "</p>\n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| Input Size | 256 |\n",
    "| Batch Size | 12 |\n",
    "| Learning Rate | $10^{-4}$ |\n",
    "| Weight Decay | $10^{-3$ |\n",
    "| Epochs Number | 75 |\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    نمودارهای خسارت بر حسب شماره\n",
    "        <span style=\"direction: rtl\">Epoch</span>\n",
    "    و دقت بر حسب شماره\n",
    "            <span style=\"direction: rtl\">Epoch</span>\n",
    "    به صورت زیر است.\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part2/accuracy.png' alt='missing' />\n",
    "        <figcaption>Accuracy-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part2/loss.png' alt='missing' />\n",
    "        <figcaption>Loss-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "</center>\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    که در کمترین خسارت، دقتی برابر ۷۸ درصد دارد. با توجه به پیچیده تر کردن مدل شبکه عصبی نسبت به قسمت قبل این نتیجه قابل انتظار است.\n",
    "</p>\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## Part 3\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به ازای مقادیر هایپر پارامترهای:\n",
    "</p>\n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| Input Size | 256 |\n",
    "| Batch Size | 12 |\n",
    "| Learning Rate | $10^{-4}$ |\n",
    "| Weight Decay | $10^{-3}$ |\n",
    "| Epochs Number | 120 |\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    نمودارهای خسارت بر حسب شماره\n",
    "        <span style=\"direction: rtl\">Epoch</span>\n",
    "    و دقت بر حسب شماره\n",
    "            <span style=\"direction: rtl\">Epoch</span>\n",
    "    به صورت زیر است.\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part3/accuracy.png' alt='missing' />\n",
    "        <figcaption>Accuracy-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part3/loss.png' alt='missing' />\n",
    "        <figcaption>Loss-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "</center>\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    که در کمترین خسارت، دقتی برابر ۸۰ درصد دارد. با توجه به اینکه مدل این قسمت، مدل\n",
    "        <span style=\"direction: rtl\">AlexNet</span>\n",
    "     است و برای آموزش شبکه عصبی با این پیچیدگی (تعداد وزن ها و بایاس های بسیار زیاد)، دیتاستی بسیار بزرگ با تنوع بالا لازم است تا مدل به خوبی آموزش یابد و قدرت تعمیم خوبی پیدا کند، قابل انتظار است که با مقادیر اولیه تصادفی مدل با دیتاست کوچک سوال به خوبی آموزش نبیند و نتیجه چندان مطلوب نباشد. (در حدود قسمت ۲)\n",
    "</p>\n",
    "\n",
    "***\n",
    "\n",
    "## Part 4\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به ازای مقادیر هایپر پارامترهای:\n",
    "</p>\n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| Input Size | 256 |\n",
    "| Batch Size | 12 |\n",
    "| Learning Rate | $10^{-4}$ |\n",
    "| Weight Decay | $10^{-4}$ |\n",
    "| Epochs Number | 45 |\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    نمودارهای خسارت بر حسب شماره\n",
    "        <span style=\"direction: rtl\">Epoch</span>\n",
    "    و دقت بر حسب شماره\n",
    "            <span style=\"direction: rtl\">Epoch</span>\n",
    "    به صورت زیر است.\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part4/accuracy.png' alt='missing' />\n",
    "        <figcaption>Accuracy-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part4/loss.png' alt='missing' />\n",
    "        <figcaption>Loss-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "</center>\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    که در کمترین خسارت، دقتی برابر ۸۳ درصد دارد. با توجه به اینکه وزن ها و بایاس های لایه های قبل از لایه آخر فریز شده و ثابت است.\n",
    "    مشابه قسمت اول می توان استدلال کرد که چرا دقت آموزش کمتر از دقت اعتبارسنجی است.\n",
    "</p>\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## Part 5\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    به ازای مقادیر هایپر پارامترهای:\n",
    "</p>\n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| Input Size | 256 |\n",
    "| Batch Size | 12 |\n",
    "| Learning Rate | .00003 |\n",
    "| Weight Decay | $10^{-3}$ |\n",
    "| Epochs Number | 45 |\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "    نمودارهای خسارت بر حسب شماره\n",
    "        <span style=\"direction: rtl\">Epoch</span>\n",
    "    و دقت بر حسب شماره\n",
    "            <span style=\"direction: rtl\">Epoch</span>\n",
    "    به صورت زیر است.\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part5/accuracy.png' alt='missing' />\n",
    "        <figcaption>Accuracy-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "    <figure>\n",
    "        <img src='./results/Part5/loss.png' alt='missing' />\n",
    "        <figcaption>Loss-Epoch</figcaption>\n",
    "    </figure>\n",
    "    <hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "</center>\n",
    "\n",
    "<p style=\"font-family: 'Vazir Thin'; text-align: right; direction: rtl\">\n",
    "     که در کمترین خسارت، دقتی برابر ۹۰ درصد دارد که همانطور که انتظار می رود با مقدار دهی اولیه وزن ها با مقادیر از پیش آموزش داده شده\n",
    "     و تنظیم دقیق آن ها به دقت خوبی رسیده ایم.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
